\chapter{Introduction}
\label{Introduction}
There are 23.14 billion IoT devices in use worldwide; by 2025 that number is broadcast to increase to 75.44 billion\cite{statista_2016}. With so many manufacturers creating IoT devices, each with differing update policies, some devices will inadvertently have better support. For example, some devices may drop out of a manufacturer's update cycle, introducing privacy and security concerns. Several large-scale cybersecurity attacks such as Mirai \cite{iotforall_2017} have already highlighted flaws in IoT security and privacy.

To address these concerns, I have built an IoT testbed that logs network and power data from 16 IoT devices over one year, accumulating 184.94 GB of data and 172,445,929 rows into a database. To help researchers sort and view this data, I have written a Python program that graphs network traffic and power data over time from the database. I then used graphs created by this tool to analyze IoT devices in the testbed while idle, during startup, and while in use. From this analysis, I characterized common patterns for each devices' network and power usage. From these graphs, I have also found that it is possible to identify the smart speaker in use when viewing just one minute of the shared power usage.

This paper focuses on addressing security and privacy flaws, that if fixed, do not affect the core features of an IoT device. For example, it is required for a smart speaker to listen to its user and store the audio in increments so that it can parse the audio for the wake word. If the smart speaker occasionally hears a false positive wake word and sends the audio to its server, that is reasonable. However, Google Homes had an issue with their wake button caused the Home to listen 24/7 \cite{burke_2017}. In another case, one of the largest IoT cybersecurity attacks, Mirai, was able to use weak login credentials to take control of 2.5 million IoT devices to perform a denial of service attack \cite{whittaker_2017}. In this case, a manufacturer cannot expect a user to change their login info and should create a more secure sign-in process. This paper uses these flaws as a focus when analyzing network and power usage.

\section{Previous Work}
This section presents and analyzes related works on the topic of analyzing and characterizing IoT devices. This section presents the previous works individually. Because these papers are similar to each other, commentary on how their work is different from ours and how it is useful to us as a group in section \ref{Scope}.

\subsection{An Analysis of Home IoT Network Traffic and Behaviour}
\label{homeIoTPaper}
The scope and work of \textit{An Analysis of Home IoT Network Traffic and Behaviour}~\cite{home_iot} are the most like the work and goals of this paper. In \textit{An Analysis of Home IoT Network Traffic and Behaviour}~\cite{home_iot}, the authors analyze IoT traffic in the home. The authors created an IoT testbed by setting up multiple IoT devices, connecting them to a router, sniffing their network packets while idle, and storing these packets on a Linux box's disk. The IoT testbed consists of a smart air quality monitor, Amazon Echo, a few Apple devices, a smart hub, and a smart vacuum cleaner.

After 22 days of network logging, the authors analyzed each IoT device individually and as a whole. For example, they noticed that they can identify most devices from the first three MAC address bits. The Hue bridge broadcasts credentials over HTTP, which is unencrypted. The authors state that these seemingly small security flaws create a privacy risk. A userâ€™s presence in a room or house can be determined from these unencrypted HTTP packets. The authors also show the percentage of network packets by protocol and various other device network patterns. This general analysis fingerprints each device.

\subsection{ProfilIoT}
\label{ProfilIoTPaper}
The paper, \textit{ProfilIoT: A Machine Learning Approach for IoT Device Identification Based on Network Traffic Analysis} ~\cite{Meidan:2017:PML:3019612.3019878} uses machine learning algorithms to classify IoT devices. The researchers of this paper collect traffic from 13 different IoT and non-IoT devices. The IOT devices include a baby monitor, motion sensor, printer, refrigerator, security camera, socket, thermostat, smartwatch, and television. The non-IoT devices include two PCs and two smartphones for comparison. These devices connect to a Wi-Fi access point that recorded their network traffic with Wire Shark\cite{wireshark}.

The researchers use machine learning on single-sessions to classify a device as an IoT device or non-IoT device. Then, they can classify the IoT devices by brand and model(e.g. Samsung Refrigerator, LG TV, WeMo Motion Sensor) with multi-sessions. A single-session is a 4-tuple formatted as source IP, destination IP, source port Number, destination port Number. When intercepting network traffic, they extract the information they need from each TCP packet to form the four-tuple data type. A multi-session is a list of single-sessions. Another machine learning model determines the minimum number of single-sessions needed to classify each device, determining the size of a multi-session. With single-sessions, they could determine if the device is an IoT device or not with 100 percent accuracy. Then out of their nine IoT devices, they can classify brand and model of the IoT device with 99.281 percent accuracy when run 7376 times.

%\subsection{Detection of Unauthorized IoT Devices Using Machine Learning Techniques}
%In the same year that ProfilIoT was released, the same group of 7 released another paper called \textit{Detection of Unauthorized IoT Devices Using Machine Learning Techniques}~\cite{meidan_2017}. In this paper, the researchers continued their work of ProfilIoT not only to classify devices but to also, given a list of whitelisted devices sets, classify a device then determine if it is a part of that whitelist. They hope to apply this to enterprise networks to prevent any unauthorized devices from connecting to it. They use the same four tuples as in the ProfilIoT paper and a bunch of other features to classify by in a random forest model. They found that time to live minimum is a significant factor in classifying the devices among other features.

\subsection{Logging and Analysis of Internet of Things (IoT) Device Network Traffic and Power Consumption}
\label{frawleyPaper}
\textit{Logging and Analysis of Internet of Things (IoT) Device Network Traffic and Power Consumption}\cite{frawley_2018}, written by Ryan Frawley, was formed in conjunction with this paper. Frawley's paper and this paper were both directed by advisor Andrew Danowitz at Cal Poly.

Frawley's paper documents the steps necessary to construct a reliable IoT testbed capable of capturing network traffic and power data for connected devices, and analyzing these devices further. He performed GeoIP\cite{maxmind} lookups on each device, showing the percentage of packets originating from each country and company. He also analyzed the packets of any unencrypted data in the devices.

\section{Scope}
\label{Scope}
The first paper from subsection \ref{homeIoTPaper} most closely matches this paper. The authors have the same overall idea to collect network data and then use it to analyze metadata surrounding the networks. Our work expands on this concept by contributing a portable database consisting of 10 months of data rather than 22 days of data. This paper adds more devices in our study and focuses more on device power/network usage over time rather than specific network packet information.

Then, like the second paper from subsection \ref{ProfilIoTPaper}, this paper also focuses on classification of devices from data. However, instead of using machine learning techniques on network data, this paper focuses on manual analysis, looking for spikes in power usage, the height of the spike, the length of the power spike, and other graphical heuristics.

In comparison to the first paper in \ref{homeIoTPaper} and second paper in \ref{ProfilIoTPaper}, this paper adds power usage over time to the data set. The two papers mentioned only focus on network traffic. This paper also puts a significant emphasis on creating an extensive database rather than a smaller set of data to create graphs on network and power usage over time.

This paper is a continuation of the third paper in subsection \ref{frawleyPaper}. Due to overlap between these two works, certain aspects of the IoT testbed setup and usage is only covered in cursory detail here. The reader is advised to access Frawley's work for full information. We both assembled the IOT test bed and interacted with the devices on a daily basis to simulate regular usage. We both also performed a preliminary analysis of the device network and power usage together.

The unique contribution of this work is its analysis of IoT device power usage and the introduction of a custom data visualization tool that attaches to the database. This paper focuses on a select few devices, analyzing their startup, idle, and in use network and power usage over time. I compare the smart speakers' network and power usage and show that it is possible to identify a smart speaker through analysis of the powerline over time.

\section{Thesis Organization}
Chapter \ref{Method} discusses my steps in setting up the IOT test bed, the analysis tool, and the logging system for interaction with devices. Chapter \ref{Method} also highlights the steps to set up a developer environment to run the analysis tool and how to use it. Chapter \ref{Results} presents power and network traffic for smart speakers and streaming devices while idle, in use, and during startup in the form of line graphs. Chapter \ref{Results} also shows the graphs used to fingerprint the smart speakers while handling different commands and under noise. Chapter \ref{Discussion} discusses the data presented in Chapter \ref{Results}, why a device might have higher throughput traffic and the feasibility of classifying devices within a household from a shared power line. Finally, Chapter \ref{Conclusion} finishes with concluding thoughts and future work.
