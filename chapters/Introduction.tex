\chapter{Introduction}
\label{Introduction}
There are 23.14 billion IoT devices in use worldwide; by 2025 that number is broadcast to increase to 75.44 billion\cite{statista_2016}. With so many manufacturers creating IoT devices, each with differing update policies, some devices will inadvertently have better support. For example, some devices may drop out of a manufacturers update cycle, introducing privacy and security concerns. Several large-scale cybersecurity attacks such as Mirai \cite{iotforall_2017} have already highlighted flaws in IoT security and privacy.

To address these concerns, I have built an IoT testbed that logs network and power data from 16 IoT devices over one year, accumulating 184.94 GB of data and 172,445,929 rows into a database. To help researchers sort and view this data, I have written a Python program that graphs network traffic and power data over time from the database. I then used graphs created by this tool to analyze IoT devices in the testbed while idle, during startup, and while in use. From this analysis, I characterized common patterns for each devices' network and power usage. From these graphs, I have also found that it is possible to identify the smart speaker in use when viewing just one minute of the shared power usage.

This paper focuses on addressing security and privacy flaws, that if fixed, do not affect the core features of an IoT device. For example, it is required for a smart speaker to listen to its user and store the audio in increments so that it can parse the audio for the wake word. If the smart speaker occasionally hears a false positive wake word and sends the audio to its server, that is reasonable. This is not what this paper will cover. However, Google Homes had an issue with their wake button caused the Home to listen 24/7 \cite{burke_2017}. In another case, one of the largest IoT cybersecurity attacks, Mirai, was able to use weak login credentials to take control of 2.5 million IoT devices to perform a denial of service attack \cite{whittaker_2017}. In this case, a manufacturer cannot expect a user to change their login info and should create a more secure sign-in process. These flaws are what this paper searches for through network and power usage.

\section{Previous Work}
This section presents and analyzes related works on the topic of analyzing and characterizing IoT devices. Here, we will present the previous works individually. Because these papers are similar to each other, we will comment on how their work is different from ours and how it is useful to us as a group in section \ref{Scope}.

\subsection{An Analysis of Home IoT Network Traffic and Behaviour}
\label{homeIoTPaper}
The scope and work of \textit{An Analysis of Home IoT Network Traffic and Behaviour}~\cite{home_iot} are the most similar to the work and goals of this paper. In \textit{An Analysis of Home IoT Network Traffic and Behaviour}~\cite{home_iot}, the authors analyze IoT traffic in the home. The authors created an IoT testbed by setting up multiple IoT devices, conecting them to a router, sniffing their network packets while idle, and storing these packets on a Linux box's disk. The IoT testbed consists of a smart air quality monitor, Amazon Echo, a few Apple devices, a smart hub, and a smart vacuum cleaner.

After 22 days of network logging, the authors analyzed each IoT device individually and as a whole. For example, they noticed that they can identify most devices from the first three MAC address bits. The Hue bridge broadcasts credentials over HTTP, which is unencrypted. The authors state that these seemingly small security flaws create a privacy risk. A users presence in a room or house can be determined from these unencrypted HTTP packets. The authors also show the percentage of network packets by protocol and various other device network patterns. This general analysis fingerprints each device.

\subsection{ProfilIoT}
\label{ProfilIoTPaper}
The paper, \textit{ProfilIoT: A Machine Learning Approach for IoT Device Identification Based on Network Traffic Analysis} ~\cite{Meidan:2017:PML:3019612.3019878} uses machine learning algorithms to classify IoT devices. The researchers of this paper collect traffic from 13 different IoT and non-IoT devices. The IOT devices include a baby monitor, motion sensor, printer, refrigerator, security camera, socket, thermostat, smartwatch, and television. The non-IoT devices include two PCs and two smartphones for comparison. These devices connect to a WiFi access point that recorded their network traffic with Wire Shark\cite{wireshark}.

The researchers use machine learning on single-sessions to classify a device as an IoT device or non-IoT device. Then, they can classify the IoT devices by brand and model(e.g. Samsung Refrigerator, LG TV, Wemo Motion Sensor) with multi-sessions. A single-session is a 4-tuple formatted as source IP, destination IP, source port Number, destination port Number. When intercepting network traffic, they extract the information they need from each TCP packet to form the four-tuple data type. A multi-session is a list of single-sessions. Another machine learning model determines the minimum number of single-sessions needed to classify each device, determining the size of a multi-session. With single-sessions, they could determine if the device is an IoT device or not with 100 percent accuracy. Then out of their nine IoT devices, they can classify brand and model of the IoT device with 99.281 percent accuracy when run 7376 times.

%\subsection{Detection of Unauthorized IoT Devices Using Machine Learning Techniques}
%In the same year that ProfilIoT was released, the same group of 7 released another paper called \textit{Detection of Unauthorized IoT Devices Using Machine Learning Techniques}~\cite{meidan_2017}. In this paper, the researchers continued their work of ProfilIoT not only to classify devices but to also, given a list of whitelisted devices sets, classify a device then determine if it is apart of that whitelist. They hope to apply this to enterprise networks to prevent any unauthorized devices from connecting to it. They use the same four tuples as in the ProfilIoT paper and a bunch of other features to classify by in a random forest model. They found that time to live minimum is a significant factor in classifying the devices among other features.

\subsection{Logging and Analysis of Internet of Things (IoT) Device Network Traffic and Power Consumption}
\label{frawleyPaper}
\textit{Logging and Analysis of Internet of Things (IoT) Device Network Traffic and Power Consumption}\cite{frawley_2018}, written by Ryan Frawley, was formed in conjunction with this paper. Frawley's paper and this paper were both directed by advisor Andrew Danowitz at Cal Poly.

Frawley's paper documents the steps necessary to construct a reliable IoT testbed capable of capturing network traffic and power data for connected devices, and analyzing these devices further. He performed GeoIP\cite{maxmind} lookups on each device, showing the percentage of packets originating from each country and company. He also analyzed the packets of any unencrypted data in the devices.

\section{Scope}
\label{Scope}
The first paper from the previous works section\cite{home_iot} most closely matches this paper. It has the same overall idea to collect network data and then uses it to analyze metadata surrounding the networks. In our paper, we do the same thing, but instead, we built a portable database consisting of 10 months of data rather than 22 days that we hope to make public. We also analyze more than the number of bytes sent by each device and looked deeper to see if the classification of devices are possible and how these devices operate over time while under operation.

The second paper from the previous works section\cite{Meidan:2017:PML:3019612.3019878} focuses more on the classification of devices from network traffic, which is we have done. However, instead of utilizing machine learning techniques as they do, we focus on manual analysis (looking for spikes in power usage, network traffic and the height of the spike, the length of the power spike, and other graphical heuristics).

In comparison to the first \cite{home_iot} and second paper \cite{Meidan:2017:PML:3019612.3019878} from the previous section, we have also added power usage over time as a data set. The two paper's mentioned only focus on network traffic. We also put a significant emphasis on creating an extensive database that others can access rather than a smaller set of data.

This paper is essentially a continuation of the third paper in the previous works section \cite{frawley_2018}. As stated in the subsection for Frawley's paper\ref{frawleyPaper}, the project spanned four school quarters at Cal Poly. Ryan started on the project the first quarter, then I joined the second quarter where we worked together for two quarters, then Frawley finished his paper, and finally I worked on this project for the last quarter independently.

In the first quarter, he worked on creating the software for the IOT test bed. Then we both put together the IOT test bed and interacted with the devices on a daily basis to simulate regular usage. Then we both analyzed various devices in tandem. Then we separately did more analysis on our own. This paper has much overlap with Frawley's paper in the setup for the testbed and analysis. The paper will state if he had already mentioned work we had both done to prevent repeated information but still state the basics so that the research is known. In comparison to Frawley's paper, this paper analyzes the device power lines more. This paper sums the power usage for multiple devices to show its possible to classify devices was possible from just one power graph.

This paper will not analyze every device within the IOT test bed. It will focus on a select few devices and provide examples of how this database and its analysis tool could be used.

\section{Contributions}
This paper intends to create a database of IOT network traffic and power data; future researchers can use this database for their research without having to set up an IOT test bed. This paper will present a way to classify what smart speaker is in use from just minutes of power information from the database. We then introduce noise into this visual classification process and provide a comparison between each smart speakers network/power usage.

We want to determine if someone could identify what device a household is using with access to the household's power line. We prove the feasibility of this through classifying a summation of power over time for multiple devices. We choose to use this as our hypotheses because power monitors are on the outside of homes and self-installation monitoring tools are out there \cite{griffith_2017}. Nowadays, some power monitors are wireless, meaning it could be remotely hacked into \cite{griffith_2017}.

\section{Thesis Organization}
In chapter \ref{Method} this paper will discuss the steps to set up the IOT test bed, the analysis tool, and the logging system for interaction with devices. This chapter highlights any steps necessary to set up the scripts we have created. Chapter \ref{Results} will present power and network traffic for a few devices in the form of line graphs. Chapter \ref{Discussion} will discuss the data presented in chapter \ref{Results}, why a particular device might have higher throughput traffic and the feasibility of classifying devices within a household from just the outside power line. Finally, chapter \ref{Conclusion} finishes with concluding thoughts and future work.